{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42b4eff9-48be-4ff5-b8ed-01ae1e904af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import warnings\n",
    "import sklearn.base\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1484fe1-8b8c-44e6-8249-08d253ee956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TherapyDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Encode categorical variables\n",
    "        self.gender_encoder = LabelEncoder()\n",
    "        self.data['gender_encoded'] = self.gender_encoder.fit_transform(self.data['Gender'])\n",
    "\n",
    "        # Encode Music and Meditation Therapies\n",
    "        self.music_therapy_encoder = LabelEncoder()\n",
    "        self.meditation_therapy_encoder = LabelEncoder()\n",
    "        self.data['music_therapy_encoded'] = self.music_therapy_encoder.fit_transform(self.data['Music Therapy'].fillna('None'))\n",
    "        self.data['meditation_therapy_encoded'] = self.meditation_therapy_encoder.fit_transform(self.data['Meditation Therapy'].fillna('None'))\n",
    "\n",
    "        # Scale numerical features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.data[['Age', 'Stress Level']] = self.scaler.fit_transform(self.data[['Age', 'Stress Level']])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        age = self.data.loc[idx, 'Age']\n",
    "        gender = self.data.loc[idx, 'gender_encoded']\n",
    "        stress_level = self.data.loc[idx, 'Stress Level']\n",
    "        text = f\"Age {age:.2f} Gender {gender} Stress {stress_level:.2f}\"\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'music_therapy_label': torch.tensor(self.data.loc[idx, 'music_therapy_encoded'], dtype=torch.long),\n",
    "            'meditation_therapy_label': torch.tensor(self.data.loc[idx, 'meditation_therapy_encoded'], dtype=torch.long),\n",
    "            'age': torch.tensor(age, dtype=torch.float),\n",
    "            'gender': torch.tensor(gender, dtype=torch.long),\n",
    "            'stress_level': torch.tensor(stress_level, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5e63c9f-2274-4d55-8701-caedd270c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TherapyRecommendationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, music_therapy_classes, meditation_therapy_classes):\n",
    "        super().__init__()\n",
    "        text_embed_dim = embedding_dim\n",
    "        feature_embed_dim = embedding_dim // 4\n",
    "\n",
    "        self.text_embedding = nn.Embedding(vocab_size, text_embed_dim)\n",
    "        self.age_embedding = nn.Linear(1, feature_embed_dim)\n",
    "        self.gender_embedding = nn.Embedding(2, feature_embed_dim)\n",
    "        self.stress_embedding = nn.Linear(1, feature_embed_dim)\n",
    "        self.feature_projector = nn.Linear(feature_embed_dim * 3, text_embed_dim)\n",
    "        self.feature_fusion = nn.TransformerEncoderLayer(\n",
    "            d_model=text_embed_dim,\n",
    "            nhead=4,\n",
    "            dim_feedforward=text_embed_dim * 2,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.music_therapy_classifier = nn.Sequential(\n",
    "            nn.Linear(text_embed_dim, text_embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(text_embed_dim // 2, music_therapy_classes)\n",
    "        )\n",
    "        self.meditation_therapy_classifier = nn.Sequential(\n",
    "            nn.Linear(text_embed_dim, text_embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(text_embed_dim // 2, meditation_therapy_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, age, gender, stress_level):\n",
    "        text_embed = self.text_embedding(input_ids)\n",
    "        age_embed = self.age_embedding(age.unsqueeze(1))\n",
    "        gender_embed = self.gender_embedding(gender)\n",
    "        stress_embed = self.stress_embedding(stress_level.unsqueeze(1))\n",
    "        additional_features = torch.cat([age_embed, gender_embed, stress_embed], dim=1)\n",
    "        projected_features = self.feature_projector(additional_features).unsqueeze(1)\n",
    "        combined_features = torch.cat([text_embed, projected_features], dim=1)\n",
    "        fused_features = self.feature_fusion(combined_features)\n",
    "        pooled_features = fused_features[:, 0]\n",
    "        music_therapy_logits = self.music_therapy_classifier(pooled_features)\n",
    "        meditation_therapy_logits = self.meditation_therapy_classifier(pooled_features)\n",
    "        return music_therapy_logits, meditation_therapy_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebf34684-9317-4428-bfd7-675f999411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            music_labels = batch['music_therapy_label'].to(device)\n",
    "            meditation_labels = batch['meditation_therapy_label'].to(device)\n",
    "            age = batch['age'].to(device)\n",
    "            gender = batch['gender'].to(device)\n",
    "            stress_level = batch['stress_level'].to(device)\n",
    "            music_logits, meditation_logits = model(input_ids, age, gender, stress_level)\n",
    "            music_loss = criterion(music_logits, music_labels)\n",
    "            meditation_loss = criterion(meditation_logits, meditation_labels)\n",
    "            total_loss = music_loss + meditation_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += total_loss.item()\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                music_labels = batch['music_therapy_label'].to(device)\n",
    "                meditation_labels = batch['meditation_therapy_label'].to(device)\n",
    "                age = batch['age'].to(device)\n",
    "                gender = batch['gender'].to(device)\n",
    "                stress_level = batch['stress_level'].to(device)\n",
    "                music_logits, meditation_logits = model(input_ids, age, gender, stress_level)\n",
    "                music_loss = criterion(music_logits, music_labels)\n",
    "                meditation_loss = criterion(meditation_logits, meditation_labels)\n",
    "                total_loss = music_loss + meditation_loss\n",
    "                total_val_loss += total_loss.item()\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss} Val Loss: {avg_val_loss}\")\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'music_therapy_encoder': train_loader.dataset.music_therapy_encoder,\n",
    "                'meditation_therapy_encoder': train_loader.dataset.meditation_therapy_encoder\n",
    "            }, 'best_therapy_model.pth')\n",
    "    return best_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c16085b-085f-45bc-89d5-527386d4f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessing_objects(train_dataset, model_path='preprocessing_objects.pkl'):\n",
    "    \n",
    "    preprocessing_objects = {\n",
    "        'music_therapy_encoder': train_dataset.music_therapy_encoder,\n",
    "        'meditation_therapy_encoder': train_dataset.meditation_therapy_encoder,\n",
    "        'gender_encoder': train_dataset.gender_encoder,\n",
    "        'scaler': train_dataset.scaler\n",
    "    }\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(preprocessing_objects, f)\n",
    "    print(f\"Preprocessing objects saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7566497-78dc-4dcb-85cf-97686ddb2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    BATCH_SIZE = 32\n",
    "    MAX_LEN = 128\n",
    "    EMBEDDING_DIM = 256\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-4\n",
    "    try:\n",
    "        df = pd.read_csv('Extended_Sleep_Health_Dataset.csv')  \n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset file not found. Please provide the correct path.\")\n",
    "        return\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    VOCAB_SIZE = len(tokenizer.vocab)\n",
    "    MUSIC_THERAPY_CLASSES = df['Music Therapy'].nunique()\n",
    "    MEDITATION_THERAPY_CLASSES = df['Meditation Therapy'].nunique()\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_dataset = TherapyDataset(train_df, tokenizer, MAX_LEN)\n",
    "    val_dataset = TherapyDataset(val_df, tokenizer, MAX_LEN)\n",
    "    save_preprocessing_objects(train_dataset)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    print(\"Number of training samples:\", len(train_df))\n",
    "    print(\"Number of validation (test) samples:\", len(val_df))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = TherapyRecommendationModel(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        music_therapy_classes=MUSIC_THERAPY_CLASSES,\n",
    "        meditation_therapy_classes=MEDITATION_THERAPY_CLASSES\n",
    "    ).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    best_loss = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        EPOCHS,\n",
    "        device\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f69411fe-cabc-48d2-a483-267fc84ae184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_therapies(age, gender, stress_level, model_path='best_therapy_model.pth', preprocessor_path='Documents/latest proj/preprocessing_objects.pkl'):\n",
    "    with open(preprocessor_path, 'rb') as f:\n",
    "        preprocessors = pickle.load(f)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TherapyRecommendationModel(\n",
    "        vocab_size=len(tokenizer.vocab),\n",
    "        embedding_dim=256,\n",
    "        music_therapy_classes=preprocessors['music_therapy_encoder'].classes_.shape[0],\n",
    "        meditation_therapy_classes=preprocessors['meditation_therapy_encoder'].classes_.shape[0]\n",
    "    ).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    age_scaled = preprocessors['scaler'].transform([[age, stress_level]])[0][0]\n",
    "    stress_scaled = preprocessors['scaler'].transform([[age, stress_level]])[0][1]\n",
    "    gender_encoded = preprocessors['gender_encoder'].transform([gender])[0]\n",
    "    text = f\"Age {age_scaled:.2f} Gender {gender_encoded} Stress {stress_scaled:.2f}\"\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    age_tensor = torch.tensor([age_scaled], dtype=torch.float).to_device()\n",
    "    gender_tensor = torch.tensor([gender_encoded], dtype=torch.long).to(device)\n",
    "    stress_tensor = torch.tensor([stress_scaled], dtype=torch.float).to(device)\n",
    "    music_logits, meditation_logits = model(\n",
    "        input_ids,\n",
    "        age_tensor,\n",
    "        gender_tensor,\n",
    "        stress_tensor\n",
    "    )\n",
    "    music_pred = torch.argmax(music_logits, dim=1).cpu().numpy()[0]\n",
    "    meditation_pred = torch.argmax(meditation_logits, dim=1).cpu().numpy()[0]\n",
    "    recommended_music = preprocessors['music_therapy_encoder'].inverse_transform([music_pred])[0]\n",
    "    recommended_meditation = preprocessors['meditation_therapy_encoder'].inverse_transform([meditation_pred])[0]\n",
    "    return recommended_music, recommended_meditation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d14f92c5-de40-4160-a42f-2167c6998da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing objects saved to preprocessing_objects.pkl\n",
      "Number of training samples: 859\n",
      "Number of validation (test) samples: 215\n",
      "Using device: cpu\n",
      "Epoch 1: Train Loss: 2.2021958651366056 Val Loss: 2.216433048248291\n",
      "Epoch 2: Train Loss: 2.2145985585671886 Val Loss: 2.2052130017961775\n",
      "Epoch 3: Train Loss: 2.213670006504765 Val Loss: 2.185236385890416\n",
      "Epoch 4: Train Loss: 2.207351057617753 Val Loss: 2.1999738216400146\n",
      "Epoch 5: Train Loss: 2.205964273876614 Val Loss: 2.2010960238320485\n",
      "Epoch 6: Train Loss: 2.200114294334694 Val Loss: 2.200970479420253\n",
      "Epoch 7: Train Loss: 2.19952834977044 Val Loss: 2.2168294361659457\n",
      "Epoch 8: Train Loss: 2.1848128813284413 Val Loss: 2.191601072038923\n",
      "Epoch 9: Train Loss: 2.1892907354566784 Val Loss: 2.2234110151018416\n",
      "Epoch 10: Train Loss: 2.19182077160588 Val Loss: 2.1935675144195557\n",
      "Best Validation Loss: 2.185236385890416\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "026f4c04-5592-46ff-a9e8-96fda915299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Therapy Recommendation System\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your age (16-36):  33\n",
      "Enter your gender (Male/Female):  male\n",
      "Enter your stress level (1-10):  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/64jdnsx95bl2xf5jgm802zhm0000gn/T/ipykernel_96945/1401606233.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recommended Therapies ---\n",
      "Top Music Therapies:\n",
      "- Singing: Purpose: to enhance brain activity (Confidence: 35.09%)\n",
      "- Listening: Purpose: for overall relaxation (Confidence: 33.64%)\n",
      "\n",
      "Top Meditation Therapies:\n",
      "- Breathing Meditation: Purpose: to manage daily stress and improve emotional regulation; Technique: Balanced breath work with gentle visualization (Confidence: 37.78%)\n",
      "- Body Scan Meditation: Purpose: to identify and address subtle stress indicators; Technique: Systematic muscle and emotional relaxation (Confidence: 32.25%)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to get another recommendation? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import warnings\n",
    "import sklearn.base\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.base\")\n",
    "\n",
    "class TherapyDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Encode categorical variables\n",
    "        self.gender_encoder = LabelEncoder()\n",
    "        self.data['gender_encoded'] = self.gender_encoder.fit_transform(self.data['Gender'])\n",
    "\n",
    "        # Encode Music and Meditation Therapies\n",
    "        self.music_therapy_encoder = LabelEncoder()\n",
    "        self.meditation_therapy_encoder = LabelEncoder()\n",
    "        self.data['music_therapy_encoded'] = self.music_therapy_encoder.fit_transform(self.data['Music Therapy'].fillna('None'))\n",
    "        self.data['meditation_therapy_encoded'] = self.meditation_therapy_encoder.fit_transform(self.data['Meditation Therapy'].fillna('None'))\n",
    "\n",
    "        # Scale numerical features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.data[['Age', 'Stress Level']] = self.scaler.fit_transform(self.data[['Age', 'Stress Level']])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        age = self.data.loc[idx, 'Age']\n",
    "        gender = self.data.loc[idx, 'gender_encoded']\n",
    "        stress_level = self.data.loc[idx, 'Stress Level']\n",
    "        text = f\"Age {age:.2f} Gender {gender} Stress {stress_level:.2f}\"\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'music_therapy_label': torch.tensor(self.data.loc[idx, 'music_therapy_encoded'], dtype=torch.long),\n",
    "            'meditation_therapy_label': torch.tensor(self.data.loc[idx, 'meditation_therapy_encoded'], dtype=torch.long),\n",
    "            'age': torch.tensor(age, dtype=torch.float),\n",
    "            'gender': torch.tensor(gender, dtype=torch.long),\n",
    "            'stress_level': torch.tensor(stress_level, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class TherapyRecommendationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, music_therapy_classes, meditation_therapy_classes):\n",
    "        super().__init__()\n",
    "        text_embed_dim = embedding_dim\n",
    "        feature_embed_dim = embedding_dim // 4\n",
    "\n",
    "        self.text_embedding = nn.Embedding(vocab_size, text_embed_dim)\n",
    "        self.age_embedding = nn.Linear(1, feature_embed_dim)\n",
    "        self.gender_embedding = nn.Embedding(2, feature_embed_dim)\n",
    "        self.stress_embedding = nn.Linear(1, feature_embed_dim)\n",
    "        self.feature_projector = nn.Linear(feature_embed_dim * 3, text_embed_dim)\n",
    "        self.feature_fusion = nn.TransformerEncoderLayer(\n",
    "            d_model=text_embed_dim,\n",
    "            nhead=4,\n",
    "            dim_feedforward=text_embed_dim * 2,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.music_therapy_classifier = nn.Sequential(\n",
    "            nn.Linear(text_embed_dim, text_embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(text_embed_dim // 2, music_therapy_classes)\n",
    "        )\n",
    "        self.meditation_therapy_classifier = nn.Sequential(\n",
    "            nn.Linear(text_embed_dim, text_embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(text_embed_dim // 2, meditation_therapy_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, age, gender, stress_level):\n",
    "        text_embed = self.text_embedding(input_ids)\n",
    "        age_embed = self.age_embedding(age.unsqueeze(1))\n",
    "        gender_embed = self.gender_embedding(gender)\n",
    "        stress_embed = self.stress_embedding(stress_level.unsqueeze(1))\n",
    "        additional_features = torch.cat([age_embed, gender_embed, stress_embed], dim=1)\n",
    "        projected_features = self.feature_projector(additional_features).unsqueeze(1)\n",
    "        combined_features = torch.cat([text_embed, projected_features], dim=1)\n",
    "        fused_features = self.feature_fusion(combined_features)\n",
    "        pooled_features = fused_features[:, 0]\n",
    "        music_therapy_logits = self.music_therapy_classifier(pooled_features)\n",
    "        meditation_therapy_logits = self.meditation_therapy_classifier(pooled_features)\n",
    "        return music_therapy_logits, meditation_therapy_logits\n",
    "\n",
    "def recommend_therapies(age, gender, stress_level, model_path='best_therapy_model.pth', preprocessor_path='preprocessing_objects.pkl'):\n",
    "    # Load preprocessors and model\n",
    "    with open(preprocessor_path, 'rb') as f:\n",
    "        preprocessors = pickle.load(f)\n",
    "    \n",
    "    # Load the trained model checkpoint\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    # Prepare tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Set up device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Prepare model\n",
    "    model = TherapyRecommendationModel(\n",
    "        vocab_size=len(tokenizer.vocab), \n",
    "        embedding_dim=256, \n",
    "        music_therapy_classes=len(preprocessors['music_therapy_encoder'].classes_),\n",
    "        meditation_therapy_classes=len(preprocessors['meditation_therapy_encoder'].classes_)\n",
    "    ).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Scale and encode inputs\n",
    "    age_stress_scaled = preprocessors['scaler'].transform([[age, stress_level]])[0]\n",
    "    age_scaled, stress_scaled = age_stress_scaled[0], age_stress_scaled[1]\n",
    "    \n",
    "    gender_encoded = preprocessors['gender_encoder'].transform([gender])[0]\n",
    "    \n",
    "    # Prepare text input\n",
    "    text = f\"Age {age_scaled:.2f} Gender {gender_encoded} Stress {stress_scaled:.2f}\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text, \n",
    "        add_special_tokens=True, \n",
    "        max_length=128, \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Prepare tensors\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    age_tensor = torch.tensor([age_scaled], dtype=torch.float).to(device)\n",
    "    gender_tensor = torch.tensor([gender_encoded], dtype=torch.long).to(device)\n",
    "    stress_tensor = torch.tensor([stress_scaled], dtype=torch.float).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        music_logits, meditation_logits = model(\n",
    "            input_ids, \n",
    "            age_tensor, \n",
    "            gender_tensor, \n",
    "            stress_tensor\n",
    "        )\n",
    "    \n",
    "    # Get top 2 music therapies\n",
    "    music_probs = torch.softmax(music_logits, dim=1).cpu().numpy()[0]\n",
    "    music_top_indices = music_probs.argsort()[-2:][::-1]\n",
    "    music_therapies = preprocessors['music_therapy_encoder'].inverse_transform(music_top_indices)\n",
    "    music_confidences = music_probs[music_top_indices]\n",
    "    \n",
    "    # Get top 2 meditation therapies\n",
    "    meditation_probs = torch.softmax(meditation_logits, dim=1).cpu().numpy()[0]\n",
    "    meditation_top_indices = meditation_probs.argsort()[-2:][::-1]\n",
    "    meditation_therapies = preprocessors['meditation_therapy_encoder'].inverse_transform(meditation_top_indices)\n",
    "    meditation_confidences = meditation_probs[meditation_top_indices]\n",
    "    \n",
    "    return (\n",
    "        list(zip(music_therapies, music_confidences)), \n",
    "        list(zip(meditation_therapies, meditation_confidences))\n",
    "    )\n",
    "\n",
    "def get_user_input():\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"\\nTherapy Recommendation System\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Age input\n",
    "            while True:\n",
    "                age = input(\"Enter your age (16-36): \")\n",
    "                try:\n",
    "                    age = int(age)\n",
    "                    if 16 <= age <= 36:\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a valid age between 16 and 36.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number.\")\n",
    "            \n",
    "            # Gender input\n",
    "            while True:\n",
    "                gender = input(\"Enter your gender (Male/Female): \").strip().capitalize()\n",
    "                if gender in ['Male', 'Female']:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter either 'Male' or 'Female'.\")\n",
    "            \n",
    "            # Stress level input\n",
    "            while True:\n",
    "                stress_level = input(\"Enter your stress level (1-10): \")\n",
    "                try:\n",
    "                    stress_level = int(stress_level)\n",
    "                    if 1 <= stress_level <= 10:\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a stress level between 1 and 10.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number.\")\n",
    "            \n",
    "            # Get recommendations\n",
    "            music_recommendations, meditation_recommendations = recommend_therapies(age, gender, stress_level)\n",
    "            \n",
    "            # Display results\n",
    "            print(\"\\n--- Recommended Therapies ---\")\n",
    "            print(\"Top Music Therapies:\")\n",
    "            for therapy, confidence in music_recommendations:\n",
    "                print(f\"- {therapy} (Confidence: {confidence*100:.2f}%)\")\n",
    "            \n",
    "            print(\"\\nTop Meditation Therapies:\")\n",
    "            for therapy, confidence in meditation_recommendations:\n",
    "                print(f\"- {therapy} (Confidence: {confidence*100:.2f}%)\")\n",
    "            \n",
    "            # Ask if user wants to continue\n",
    "            continue_choice = input(\"\\nDo you want to get another recommendation? (yes/no): \").lower()\n",
    "            if continue_choice != 'yes':\n",
    "                break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# Run the recommendation system\n",
    "if __name__ == \"__main__\":\n",
    "    get_user_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929499aa-f62b-46b4-93d9-20f82322f1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
